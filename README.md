# ğŸ“Š PrevisÃ£o de EvasÃ£o de Clientes (Churn) da TelecomX - Modelos de Machine Learning

## ğŸ¯ Objetivo

Este projeto tem como foco a anÃ¡lise de evasÃ£o de clientes (churn) da empresa **TelecomX**, utilizando dados histÃ³ricos para identificar padrÃµes comportamentais e contratuais que influenciam a saÃ­da dos clientes. A partir dessa anÃ¡lise, o objetivo Ã© construir modelos preditivos capazes de antecipar o risco de churn, contribuindo para estratÃ©gias de retenÃ§Ã£o mais eficazes.

---

## ğŸ§  Metodologia

A abordagem adotada seguiu um pipeline completo de ciÃªncia de dados, com as seguintes etapas:

### 1. PreparaÃ§Ã£o e NormalizaÃ§Ã£o dos Dados

- As variÃ¡veis categÃ³ricas foram transformadas em binÃ¡rias (0 ou 1).
- VariÃ¡veis contÃ­nuas como `customer.tenure`, `account.Charges.Monthly` e `account.Charges.Total` mantiveram suas escalas originais.
- Para garantir uniformidade, os dados foram normalizados entre 0 e 1 utilizando o mÃ©todo `MinMaxScaler` da biblioteca `sklearn.preprocessing`.

###  Balanceamento de Dados
  
Como a variÃ¡vel resposta (Churn) apresenta desbalanceamento entre classes, foram utilizadas tÃ©cnicas para equilibrar os dados.

ğŸ”¸ Oversampling

Aumenta a quantidade de dados da classe minoritÃ¡ria atÃ© igualar Ã  classe majoritÃ¡ria. Dessa forma, o modelo aprende melhor os padrÃµes da classe menos representada.
from imblearn.over_sampling import SMOTE


ğŸ”¸ Undersampling

Reduz a quantidade de dados da classe majoritÃ¡ria atÃ© igualar Ã  classe minoritÃ¡ria. Isso evita que o modelo se concentre excessivamente na classe dominante.
from imblearn.under_sampling import NearMiss



- ValidaÃ§Ã£o Cruzada com Pipeline

Foi utilizado o mÃ©todo StratifiedKFold para garantir que a proporÃ§Ã£o das classes seja mantida em cada divisÃ£o. A biblioteca imblearn permite automatizar o processo de validaÃ§Ã£o cruzada com tÃ©cnicas de oversampling ou undersampling integradas ao pipeline.
from sklearn.model_selection import StratifiedKFold


Essa abordagem garante que o balanceamento dos dados ocorra dentro de cada fold, evitando vazamento de dados e proporcionando uma avaliaÃ§Ã£o mais robusta dos modelos.

ğŸ› ï¸ Ferramentas e Bibliotecas
- Python â€“ Linguagem principal do projeto
- pandas â€“ ManipulaÃ§Ã£o de dados
- matplotlib, seaborn, plotly.express â€“ VisualizaÃ§Ã£o grÃ¡fica
- scikit-learn â€“ Modelos de machine learning, prÃ©-processamento e validaÃ§Ã£o
- imblearn â€“ TÃ©cnicas de balanceamento e integraÃ§Ã£o com pipelines
- MinMaxScaler â€“ NormalizaÃ§Ã£o de variÃ¡veis contÃ­nuas


## Modelos de ClassificaÃ§Ã£o Utilizados

### ğŸ”¹ Modelo Base (Dummy)

O modelo base serve como referÃªncia para avaliar o desempenho dos demais algoritmos. Ele realiza previsÃµes simples, como sempre escolher a classe majoritÃ¡ria, sem considerar os dados de entrada. Ã‰ Ãºtil para estabelecer um ponto de partida mÃ­nimo de performance.

### ğŸ”¹ Ãrvore de DecisÃ£o

A Ãrvore de DecisÃ£o Ã© um modelo interpretÃ¡vel que segmenta os dados em ramos com base em perguntas binÃ¡rias sobre os atributos. A profundidade da Ã¡rvore (`max_depth`) influencia diretamente sua capacidade de generalizaÃ§Ã£o: Ã¡rvores muito profundas tendem a sobreajustar os dados, enquanto Ã¡rvores rasas podem subestimar padrÃµes importantes.

### ğŸ”¹ Random Forest

O Random Forest Ã© um modelo de conjunto (ensemble) que combina vÃ¡rias Ã¡rvores de decisÃ£o independentes. Cada Ã¡rvore Ã© treinada com uma amostra aleatÃ³ria dos dados e dos atributos, e a decisÃ£o final Ã© tomada por votaÃ§Ã£o. Essa abordagem reduz o risco de sobreajuste e melhora a robustez do modelo.

### ğŸ”¹ KNN (K-Nearest Neighbors)

O KNN Ã© um algoritmo baseado em instÃ¢ncias que classifica um exemplo com base na maioria das classes dos seus vizinhos mais prÃ³ximos. O parÃ¢metro `n_neighbors` define quantos vizinhos serÃ£o considerados. O desempenho do KNN depende da escala dos dados e da escolha adequada de `n_neighbors`.

----
Este projeto representa uma aplicaÃ§Ã£o prÃ¡tica de ciÃªncia de dados voltada Ã  inteligÃªncia de negÃ³cios, com potencial direto de impacto na reduÃ§Ã£o da evasÃ£o de clientes da TelecomX.
